{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG_VQA.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"FrnHzklAsBmt"},"source":["# INTRO"]},{"cell_type":"code","metadata":{"id":"KJqHEF3eT6Zn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2424b858-b3d0-4893-b837-d5fe215099ab"},"source":["from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","\n","import os\n","import tensorflow as tf\n","import numpy as np\n","import json\n","\n","\n","# Set the seed for random operations. \n","# This let our experiments to be reproducible. \n","SEED = 1234\n","tf.random.set_seed(SEED)\n","np.random.seed(SEED)\n","\n","# Get current working directory\n","cwd = os.getcwd()\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","data_dir=r\"/content/drive/MyDrive/anndl-2020-vqa.zip (Unzipped Files)/VQA_Dataset\"\n","image_dir=r\"/content/drive/MyDrive/anndl-2020-vqa.zip (Unzipped Files)/VQA_Dataset/Images\"\n","\n","os.listdir(data_dir)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['Images', 'test_questions.json', 'train_questions_annotations.json', 'Splits']"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"N1e23RyaQDuU"},"source":["# PREPROCESSING TEXT"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YKBe8oThPvRe","outputId":"af822811-983f-477b-9b35-13db4fc84c02"},"source":["question_sentences = []\r\n","answer = []\r\n","question_sentences_test = []\r\n","\r\n","\r\n","f=open(os.path.join(data_dir, 'train_questions_annotations.json'), encoding='utf-8')\r\n","g=json.load(f)\r\n","count=0\r\n","for line in g:\r\n","  answer.append(g[line]['answer'] ) \r\n","  h=g[line]['question']\r\n","  question_sentences.append( '<sos>' + h.replace('?', ''))\r\n","\r\n","length=len(answer)\r\n","\r\n","type(question_sentences[0])\r\n","print('\\n')\r\n","\r\n","f=open(os.path.join(data_dir, 'test_questions.json'), encoding='utf-8')\r\n","g=json.load(f)\r\n","for line in g:\r\n","  h=g[line]['question']\r\n","  question_sentences_test.append( '<sos>' + h.replace('?', ''))\r\n","\r\n","\r\n","from tensorflow.keras.preprocessing.text import Tokenizer\r\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n","\r\n","MAX_NUM_WORDS=60000\r\n","\r\n","# Create Tokenizer to convert words to integers\r\n","quest_tokenizer = Tokenizer(num_words= MAX_NUM_WORDS)\r\n","quest_tokenizer.fit_on_texts(question_sentences)\r\n","quest_tokenized = quest_tokenizer.texts_to_sequences(question_sentences)\r\n","\r\n","quest_wtoi = quest_tokenizer.word_index\r\n","print('Total question words:', len(quest_wtoi))\r\n","max_quest_length = max(len(sentence) for sentence in quest_tokenized)\r\n","print('Max question sentence length:', max_quest_length)\r\n","quest_encoder_inputs = pad_sequences(quest_tokenized, maxlen=max_quest_length)\r\n","type(quest_encoder_inputs)\r\n","\r\n","\r\n","\r\n","num_answers=58\r\n","labels_dict =  {\r\n","        '0': 0,\r\n","        '1': 1,\r\n","        '2': 2,\r\n","        '3': 3,\r\n","        '4': 4,\r\n","        '5': 5,\r\n","        'apple': 6,\r\n","        'baseball': 7,\r\n","        'bench': 8,\r\n","        'bike': 9,\r\n","        'bird': 10,\r\n","        'black': 11,\r\n","        'blanket': 12,\r\n","        'blue': 13,\r\n","        'bone': 14,\r\n","        'book': 15,\r\n","        'boy': 16,\r\n","        'brown': 17,\r\n","        'cat': 18,\r\n","        'chair': 19,\r\n","        'couch': 20,\r\n","        'dog': 21,\r\n","        'floor': 22,\r\n","        'food': 23,\r\n","        'football': 24,\r\n","        'girl': 25,\r\n","        'grass': 26,\r\n","        'gray': 27,\r\n","        'green': 28,\r\n","        'left': 29,\r\n","        'log': 30,\r\n","        'man': 31,\r\n","        'monkey bars': 32,\r\n","        'no': 33,\r\n","        'nothing': 34,\r\n","        'orange': 35,\r\n","        'pie': 36,\r\n","        'plant': 37,\r\n","        'playing': 38,\r\n","        'red': 39,\r\n","        'right': 40,\r\n","        'rug': 41,\r\n","        'sandbox': 42,\r\n","        'sitting': 43,\r\n","        'sleeping': 44,\r\n","        'soccer': 45,\r\n","        'squirrel': 46,\r\n","        'standing': 47,\r\n","        'stool': 48,\r\n","        'sunny': 49,\r\n","        'table': 50,\r\n","        'tree': 51,\r\n","        'watermelon': 52,\r\n","        'white': 53,\r\n","        'wine': 54,\r\n","        'woman': 55,\r\n","        'yellow': 56,\r\n","        'yes': 57\r\n","  }\r\n","\r\n","\r\n","ans_indices = [labels_dict[a] for a in answer]\r\n","ans_Y = tf.keras.utils.to_categorical(ans_indices)\r\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["str"]},"metadata":{"tags":[]},"execution_count":2},{"output_type":"stream","text":["\n","\n","Total question words: 4641\n","Max question sentence length: 22\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"RvnrFaBTWg8q"},"source":["# PREPROCESSING IMAGE\n"]},{"cell_type":"code","metadata":{"id":"LX4woViiVLL1"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n","\r\n","apply_data_augmentation = False\r\n","\r\n","# Create training ImageDataGenerator object\r\n","\r\n","if apply_data_augmentation:\r\n","    img_data_gen = ImageDataGenerator(rotation_range=10,\r\n","                                      width_shift_range=10,\r\n","                                      height_shift_range=10,\r\n","                                      zoom_range=0.3,\r\n","                                      horizontal_flip=True,\r\n","                                      vertical_flip=True,\r\n","                                      fill_mode='reflect')\r\n","else:\r\n","    img_data_gen = ImageDataGenerator(rescale=1./255)\r\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pb908tTuOVZm"},"source":["from PIL import Image\r\n","\r\n","class CustomDataset(tf.keras.utils.Sequence):\r\n","\r\n","  \"\"\"\r\n","    CustomDataset inheriting from tf.keras.utils.Sequence.\r\n","\r\n","    3 main methods:\r\n","      - __init__: save dataset params like directory, filenames..\r\n","      - __len__: return the total number of samples in the dataset\r\n","      - __getitem__: return a sample from the dataset\r\n","\r\n","    Note: \r\n","      - the custom dataset return a single sample from the dataset. Then, we use \r\n","        a tf.data.Dataset object to group samples into batches.\r\n","      - in this case we have a different structure of the dataset in memory. \r\n","        We have all the images in the same folder and the training and validation splits\r\n","        are defined in text files.\r\n","\r\n","  \"\"\"\r\n","\r\n","  def __init__(self, dataset_dir, which_subset, img_generator=None, mask_generator=None, \r\n","               preprocessing_function=None, out_shape=[256, 256]):\r\n","    \r\n","\r\n","    f=open(os.path.join(data_dir, 'train_questions_annotations.json'), encoding='utf-8')   \r\n","    subset_file=json.load(f)\r\n","    \r\n","    subset_filenames = []\r\n","    answer=[]\r\n","\r\n","    for line in subset_file:\r\n","      subset_filenames.append(subset_file[line]['image_id'])\r\n","      \r\n","    \r\n","    \r\n","    self.which_subset = which_subset\r\n","    self.dataset_dir = dataset_dir\r\n","    self.subset_filenames = subset_filenames\r\n","    self.img_generator = img_generator\r\n","    self.preprocessing_function = preprocessing_function\r\n","    self.out_shape = out_shape\r\n","\r\n","  def __len__(self):\r\n","    return len(self.subset_filenames)\r\n","\r\n","  def __getitem__(self, index):\r\n","    # Read Image\r\n","    curr_filename = self.subset_filenames[index]\r\n","    img = Image.open(os.path.join(self.dataset_dir, 'Images', curr_filename + '.png'))\r\n","    \r\n","\r\n","    # Resize image and mask\r\n","    img = img.resize([256,256]) ##MANUALE\r\n","    \r\n","    img_arr = np.array(img)[...,:3]\r\n","    arr=img_arr\r\n","    img_arr = ((arr - arr.min()) * (1/(arr.max() - arr.min()) * 255)).astype('uint8')\r\n","\r\n","\r\n","\r\n","    if self.which_subset == 'training':\r\n","      if self.img_generator is not None:\r\n","        # Perform data augmentation\r\n","        # We can get a random transformation from the ImageDataGenerator using get_random_transform\r\n","        # and we can apply it to the image using apply_transform\r\n","        img_t = self.img_generator.get_random_transform(img_arr.shape, seed=SEED)\r\n","        img_arr = self.img_generator.apply_transform(img_arr, img_t)\r\n","        # ImageDataGenerator use bilinear interpolation for augmenting the images.\r\n","        \r\n","    \r\n","      \r\n","    \r\n","    if self.preprocessing_function is not None:\r\n","      img_arr = self.preprocessing_function(img_arr)\r\n","    \r\n","    q=quest_encoder_inputs[index] ##extract from text preprocessing\r\n","  \r\n","    a=ans_Y[index]\r\n","\r\n","    #inputs=(img_arr,q)\r\n","    inputs={'input_2': img_arr,'input_3':q}\r\n","\r\n","    output=a\r\n","\r\n","    return inputs,output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LF5hkwhsOn-Z"},"source":["from tensorflow.keras.applications.vgg16 import preprocess_input \r\n","\r\n","img_h = 256\r\n","img_w = 256\r\n","\r\n","dataset = CustomDataset(data_dir, 'training', \r\n","                        img_generator=img_data_gen,  #else=img_data_gen\r\n","                        preprocessing_function=preprocess_input)\r\n","\r\n","\r\n","\r\n","types = ( (tf.float32,tf.int64), (tf.int64) ) \r\n","shapes = (([img_h, img_w, 3],[max_quest_length]),\r\n","          [58])\r\n","\r\n","types2= ( { 'input_2':tf.float32, 'input_3' : tf.int64}, tf.int64) \r\n","shapes2 = ({ 'input_2':[img_h, img_w, 3], 'input_3' : [max_quest_length]},\r\n","          [58])\r\n","\r\n","full_dataset = tf.data.Dataset.from_generator(lambda: dataset,\r\n","                                               output_types=types2,\r\n","                                               output_shapes=shapes2)\r\n","\r\n","bs=32\r\n","train_size = int(0.8 * length)\r\n","valid_size=length-train_size\r\n","\r\n","#full_dataset = full_dataset.shuffle()\r\n","train_dataset = full_dataset.take(train_size)\r\n","valid_dataset = full_dataset.skip(train_size)\r\n","\r\n","\r\n","train_dataset = train_dataset.batch(bs)\r\n","train_dataset = train_dataset.repeat()\r\n","valid_dataset = valid_dataset.batch(bs)\r\n","valid_dataset = valid_dataset.repeat()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tn1uuNPvb9Co","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"31c521a0-3cf1-42fa-a381-101719d89a76"},"source":["# Let's test data generator\r\n","# -------------------------\r\n","import time\r\n","from matplotlib import cm\r\n","import matplotlib.pyplot as plt\r\n","\r\n","%matplotlib inline\r\n","\r\n","\r\n","train_dataset\r\n","next(iter(train_dataset))[0]['input_2']\r\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<RepeatDataset shapes: ({input_2: (None, 256, 256, 3), input_3: (None, 22)}, (None, 58)), types: ({input_2: tf.float32, input_3: tf.int64}, tf.int64)>"]},"metadata":{"tags":[]},"execution_count":6},{"output_type":"error","ename":"UnknownError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2112\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2114\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2579\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2580\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n","\u001b[0;31mUnknownError\u001b[0m: OSError: [Errno 5] Input/output error: '/content/drive/MyDrive/anndl-2020-vqa.zip (Unzipped Files)/VQA_Dataset/Images/11779.png'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 483, in __iter__\n    for item in (self[i] for i in range(len(self))):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 483, in <genexpr>\n    for item in (self[i] for i in range(len(self))):\n\n  File \"<ipython-input-4-6870973b5dea>\", line 50, in __getitem__\n    img = Image.open(os.path.join(self.dataset_dir, 'Images', curr_filename + '.png'))\n\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2809, in open\n    fp = builtins.open(filename, \"rb\")\n\nOSError: [Errno 5] Input/output error: '/content/drive/MyDrive/anndl-2020-vqa.zip (Unzipped Files)/VQA_Dataset/Images/11779.png'\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-50aed49348c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2114\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2116\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnknownError\u001b[0m: OSError: [Errno 5] Input/output error: '/content/drive/MyDrive/anndl-2020-vqa.zip (Unzipped Files)/VQA_Dataset/Images/11779.png'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 483, in __iter__\n    for item in (self[i] for i in range(len(self))):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 483, in <genexpr>\n    for item in (self[i] for i in range(len(self))):\n\n  File \"<ipython-input-4-6870973b5dea>\", line 50, in __getitem__\n    img = Image.open(os.path.join(self.dataset_dir, 'Images', curr_filename + '.png'))\n\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2809, in open\n    fp = builtins.open(filename, \"rb\")\n\nOSError: [Errno 5] Input/output error: '/content/drive/MyDrive/anndl-2020-vqa.zip (Unzipped Files)/VQA_Dataset/Images/11779.png'\n\n\n\t [[{{node PyFunc}}]]"]}]},{"cell_type":"markdown","metadata":{"id":"JSR_e9lfPzct"},"source":["# MODEL"]},{"cell_type":"code","metadata":{"id":"UpD3FPjtK-fw","colab":{"base_uri":"https://localhost:8080/","height":903},"outputId":"d1be3fda-0809-4d8d-a05d-fc9818703fdb"},"source":["# Import Keras \n","from keras.layers import Conv2D, MaxPooling2D, Flatten\n","from keras.layers import Input, LSTM, Embedding, Dense\n","from keras.models import Model, Sequential\n","\n","vgg = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n","\n","finetuning=True\n","\n","if finetuning:\n","    freeze_until = -6 \n","    \n","    for layer in vgg.layers[:freeze_until]:\n","        layer.trainable = False\n","else:\n","    vgg.trainable = False\n","\n","\n","# Define CNN for Image Input\n","vision_model = Sequential()\n","vision_model.add(vgg)\n","vision_model.add(Flatten())\n","\n","image_input = Input(shape=(256, 256,3)) #remove 3 in fondo\n","encoded_image = vision_model(image_input)\n","\n","# Define RNN for language input\n","EMBEDDING_SIZE = 32\n","\n","question_input = Input(shape=[max_quest_length])\n","embedded_question = Embedding(len(quest_wtoi)+1, EMBEDDING_SIZE, input_length=max_quest_length)(question_input)\n","encoded_question = LSTM(EMBEDDING_SIZE)(embedded_question)\n","\n","from tensorflow.keras.layers import Multiply\n","# Combine CNN and RNN to create the final model\n","#merged = tf.keras.layers.concatenate([encoded_question, encoded_image]) Multiply()\n","\n","merged = tf.keras.layers.concatenate([encoded_question, encoded_image])\n","output = Dense(58, activation='softmax')(merged)\n","model = Model(inputs=[image_input, question_input], outputs=output)\n","\n","model.summary()\n","tf.keras.utils.plot_model(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 0s 0us/step\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, 22)]         0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 22, 32)       148544      input_3[0][0]                    \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     (None, 32)           8320        embedding[0][0]                  \n","__________________________________________________________________________________________________\n","sequential (Sequential)         (None, 32768)        14714688    input_2[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 32800)        0           lstm[0][0]                       \n","                                                                 sequential[0][0]                 \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 58)           1902458     concatenate[0][0]                \n","==================================================================================================\n","Total params: 16,774,010\n","Trainable params: 11,498,554\n","Non-trainable params: 5,275,456\n","__________________________________________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"image/png":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"AlbGCZQUT6Zp"},"source":["# Optimization params\n","# -------------------\n","\n","# Loss\n","loss = tf.keras.losses.CategoricalCrossentropy\n","\n","# learning rate\n","lr = 1e-3\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","# -------------------\n","\n","# Validation metrics\n","# ------------------\n","\n","metrics = ['accuracy']\n","# ------------------\n","\n","# Compile Model\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=metrics)\n","\n","import os\n","from datetime import datetime\n","\n","cwd = os.getcwd()\n","\n","exps_dir = os.path.join('/content/drive/My Drive/KerasRNN', 'translation_experiments')\n","if not os.path.exists(exps_dir):\n","    os.makedirs(exps_dir)\n","\n","now = datetime.now().strftime('%b%d_%H-%M-%S')\n","\n","exp_name = 'exp'\n","\n","exp_dir = os.path.join(exps_dir, exp_name + '_' + str(now))\n","if not os.path.exists(exp_dir):\n","    os.makedirs(exp_dir)\n","    \n","callbacks = []\n","\n","# Model checkpoint\n","# ----------------\n","ckpt_dir = os.path.join(exp_dir, 'ckpts')\n","if not os.path.exists(ckpt_dir):\n","    os.makedirs(ckpt_dir)\n","\n","ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n","                                                   save_weights_only=True)  # False to save the model directly\n","callbacks.append(ckpt_callback)\n","\n","# ----------------\n","\n","# Visualize Learning on Tensorboard\n","# ---------------------------------\n","tb_dir = os.path.join(exp_dir, 'tb_logs')\n","if not os.path.exists(tb_dir):\n","    os.makedirs(tb_dir)\n","    \n","# By default shows losses and metrics for both training and validation\n","tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n","                                             profile_batch=0,\n","                                             histogram_freq=1)  # if 1 shows weights histograms\n","callbacks.append(tb_callback)\n","\n","# Early Stopping\n","# --------------\n","early_stop = True\n","if early_stop:\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n","    callbacks.append(es_callback)\n","\n","# ---------------------------------\n","\n","\n","\n","# How to visualize Tensorboard\n","\n","# 1. tensorboard --logdir EXPERIMENTS_DIR --port PORT     <- from terminal\n","# 2. localhost:PORT   <- in your browser"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rINDnDXeq5WF"},"source":["# RUNN"]},{"cell_type":"code","metadata":{"id":"YXvh19UH9fLL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"15b1cf7e-6bd5-48e0-8a89-7f79ca33e573"},"source":["\r\n","model.fit(\r\n","  x=train_dataset,\r\n","  shuffle=True,\r\n","  epochs=20,\r\n","  steps_per_epoch=train_size/bs,\r\n","  validation_data=valid_dataset,\r\n","  validation_steps=valid_size/bs,\r\n","  callbacks=callbacks\r\n",")\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","1470/1470 [==============================] - 10194s 7s/step - loss: 3.2557 - accuracy: 0.3018 - val_loss: 1.5929 - val_accuracy: 0.4341\n","Epoch 2/20\n","1470/1470 [==============================] - 2150s 1s/step - loss: 1.5771 - accuracy: 0.4285 - val_loss: 1.4502 - val_accuracy: 0.4717\n","Epoch 3/20\n","1470/1470 [==============================] - 2057s 1s/step - loss: 1.4166 - accuracy: 0.4734 - val_loss: 1.3183 - val_accuracy: 0.4954\n","Epoch 4/20\n","1470/1470 [==============================] - 2136s 1s/step - loss: 1.2696 - accuracy: 0.5206 - val_loss: 1.2204 - val_accuracy: 0.5379\n","Epoch 5/20\n","1470/1470 [==============================] - 2076s 1s/step - loss: 1.1723 - accuracy: 0.5587 - val_loss: 1.1683 - val_accuracy: 0.5576\n","Epoch 6/20\n","1470/1470 [==============================] - 2295s 2s/step - loss: 1.1044 - accuracy: 0.5808 - val_loss: 1.1337 - val_accuracy: 0.5685\n","Epoch 7/20\n","1470/1470 [==============================] - 2068s 1s/step - loss: 1.0558 - accuracy: 0.5979 - val_loss: 1.1083 - val_accuracy: 0.5797\n","Epoch 8/20\n","1470/1470 [==============================] - 2066s 1s/step - loss: 1.0175 - accuracy: 0.6082 - val_loss: 1.0939 - val_accuracy: 0.5842\n","Epoch 9/20\n","1256/1470 [========================>.....] - ETA: 2:35 - loss: 0.9876 - accuracy: 0.6152"],"name":"stdout"}]}]}
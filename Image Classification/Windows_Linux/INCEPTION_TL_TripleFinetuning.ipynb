{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"INCEPTION_TL_TripleFinetuning.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ybyKhjNDrfbO"},"source":["# Transfer Learning approach - InceptionResNetV2\n","In this notebook we have adopted a double finetuning technique based on the InceptionResNetV2 pre-trained model."]},{"cell_type":"markdown","metadata":{"id":"6s998L4ur-C5"},"source":["Import the needed libraries and connect Drive:"]},{"cell_type":"code","metadata":{"id":"NlVIKsRvQiUQ"},"source":["from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j5hKGPULQjct"},"source":["import os\n","import tensorflow as tf\n","import numpy as np\n","import shutil\n","\n","SEED = 1518\n","tf.random.set_seed(SEED)  \n","\n","# Get current working directory\n","cwd = os.getcwd()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ZNqh4LDcnjW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605809976556,"user_tz":-60,"elapsed":27704,"user":{"displayName":"Davide Caffù","photoUrl":"","userId":"02628019914579525099"}},"outputId":"b74b45a3-7529-468d-b818-38c3db9f1454"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qvpn-gBLeMxc"},"source":["# Get dataset directory\n","dataset_dir = os.path.join(cwd, 'drive/My Drive/MaskDataset')\n","dataset_dir\n","train_dir=os.path.join(dataset_dir,'training')\n","test_dir = os.path.join(dataset_dir, 'test')\n","os.listdir(dataset_dir)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mzOR4Mn-Q9Iw"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","apply_data_augmentation = True\n","\n","# Create training ImageDataGenerator object\n","if apply_data_augmentation:\n","    train_data_gen = ImageDataGenerator(rotation_range=30,\n","                                        width_shift_range=10,\n","                                        height_shift_range=10,\n","                                        zoom_range=0.2,\n","                                        horizontal_flip=True,\n","                                        vertical_flip=False,\n","                                        fill_mode='nearest',\n","                                        rescale=1./255,\n","                                        validation_split=0.2)\n","else:\n","    train_data_gen = ImageDataGenerator(rescale=1./255,\n","                                        validation_split=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5nIjmwVDxpMF"},"source":["# Batch size\n","bs = 8\n","\n","# Image shape forced\n","img_width = 256\n","img_height = 256\n","\n","# Classes\n","num_classes = 3\n","\n","# Generate Training & Validation\n","train_gen = train_data_gen.flow_from_directory(train_dir,\n","                                               batch_size=bs,\n","                                               classes=None,\n","                                               class_mode='categorical', ##automatic 1-hot encoding\n","                                               color_mode='rgb',        \n","                                               shuffle=True,\n","                                               subset='training',\n","                                               seed=SEED) \n","valid_gen = train_data_gen.flow_from_directory(train_dir,\n","                                               batch_size=bs,\n","                                               classes=None,\n","                                               class_mode='categorical', ##automatic 1-hot encoding\n","                                               color_mode='rgb',        \n","                                               shuffle=True,\n","                                               subset='validation',\n","                                               seed=SEED)\n","\n","\n","\n","# Training set creation (85pc) and valid set creation(15pc)\n","train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([None, img_height, img_width, 3], [None, num_classes]))\n","valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([None, img_height, img_width, 3], [None, num_classes]))\n","\n","# Repeat()\n","train_dataset.repeat()\n","valid_dataset.repeat()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"87KkmM7Vwtlu"},"source":["Load the InceptionResNetV2 model. Loaded weights are the ones of the network trained on the *ImageNet* database. The fully-connected part is removed by setting include_top to False."]},{"cell_type":"code","metadata":{"id":"H6jkcc69hEcN"},"source":["# Load InceptionResNetV2 Model\n","\n","Inc = tf.keras.applications.InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ojskSIlBogpP"},"source":["First finetuning: layers of the base are freezed until the 50th"]},{"cell_type":"code","metadata":{"id":"AWIxwN3l5a9f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605810286732,"user_tz":-60,"elapsed":4742,"user":{"displayName":"Davide Caffù","photoUrl":"","userId":"02628019914579525099"}},"outputId":"617dd2ed-0202-4713-d9f7-77d003b6b0f0"},"source":["# Create Model\n","\n","finetuning = True\n","\n","if finetuning:\n","    freeze_until = 50\n","    \n","    for layer in Inc.layers[:freeze_until]:\n","        layer.trainable = False\n","    for layer in Inc.layers[freeze_until:]:\n","        layer.trainable = True    \n","else:\n","    Inc.trainable = False\n","    \n","model = tf.keras.Sequential()\n","model.add(Inc)\n","model.add(tf.keras.layers.GlobalAveragePooling2D())\n","model.add(tf.keras.layers.Dense(units=256, activation='relu', kernel_regularizer='l2'))\n","model.add(tf.keras.layers.Dropout(0.55))\n","model.add(tf.keras.layers.Dense(units=64, activation='relu', kernel_regularizer='l2'))\n","model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n","\n","# Model summary\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","inception_resnet_v2 (Functio (None, 6, 6, 1536)        54336736  \n","_________________________________________________________________\n","global_average_pooling2d_1 ( (None, 1536)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 256)               393472    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 64)                16448     \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 3)                 195       \n","=================================================================\n","Total params: 54,746,851\n","Trainable params: 54,211,827\n","Non-trainable params: 535,024\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TYBq_Quwo8qW"},"source":["Set optimization parameters: loss, optimizer and metrics"]},{"cell_type":"code","metadata":{"id":"rW1lXDp5o9T9"},"source":["# Loss\n","loss = tf.keras.losses.CategoricalCrossentropy()\n","\n","# learning rate\n","lr = 1e-4\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","\n","# Validation metrics\n","metrics = ['accuracy']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UbpxvWN8yOVw"},"source":["# Compile Model\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"70hJ3NQHpKtd"},"source":["Load tensorboard (uncomment to load)"]},{"cell_type":"code","metadata":{"id":"oEFBqJpWgQ04"},"source":["#%reload_ext tensorboard\n","#%tensorboard --logdir /content/drive/My\\ Drive/MaskDataset/classification_experiments --port 8008"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KRhjQDI4pXLN"},"source":["Set callbacks and visualization of losses and metrics on Tensorboard"]},{"cell_type":"code","metadata":{"id":"X9yj1Wrjd_1i"},"source":["# Callbacks\n","\n","from datetime import datetime\n","\n","\n","cwd = os.getcwd()\n","\n","exps_dir = os.path.join('/content/drive/My Drive/MaskDataset/', 'classification_experiments_Inc')\n","if not os.path.exists(exps_dir):\n","    os.makedirs(exps_dir)\n","\n","now = datetime.now().strftime('%b%d_%H-%M-%S')\n","\n","model_name = 'CNN_1'\n","\n","exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n","if not os.path.exists(exp_dir):\n","    os.makedirs(exp_dir)\n","    \n","callbacks = []\n","\n","# Visualize Learning on Tensorboard\n","tb_dir = os.path.join(exp_dir, 'tb_logs')\n","if not os.path.exists(tb_dir):\n","    os.makedirs(tb_dir)\n","    \n","# Shows losses and metrics for both training and validation\n","tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n","                                             profile_batch=0,\n","                                             histogram_freq=1)  # if 1 shows weights histograms\n","callbacks.append(tb_callback)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VNwFR9jLplNM"},"source":["Apply Early Stopping"]},{"cell_type":"code","metadata":{"id":"WtugeVcYplrd"},"source":["# Early Stopping\n","\n","early_stop = True\n","if early_stop:\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n","    callbacks.append(es_callback)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UgEr-3kmfEWy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605818073160,"user_tz":-60,"elapsed":7786713,"user":{"displayName":"Davide Caffù","photoUrl":"","userId":"02628019914579525099"}},"outputId":"c717348a-2d8f-4b7f-e28a-c417c74e7bd8"},"source":["# Model fitting\n","\n","model.fit(x=train_dataset,\n","          epochs=100,\n","          steps_per_epoch=len(train_gen),\n","          validation_data=valid_dataset,\n","          validation_steps=len(valid_gen), \n","          callbacks=callbacks)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","563/563 [==============================] - 1273s 2s/step - loss: 4.5242 - accuracy: 0.7099 - val_loss: 3.1815 - val_accuracy: 0.8238\n","Epoch 2/100\n","563/563 [==============================] - 237s 421ms/step - loss: 2.4884 - accuracy: 0.8405 - val_loss: 2.0498 - val_accuracy: 0.8301\n","Epoch 3/100\n","563/563 [==============================] - 233s 414ms/step - loss: 1.5306 - accuracy: 0.8767 - val_loss: 1.1993 - val_accuracy: 0.8986\n","Epoch 4/100\n","563/563 [==============================] - 232s 412ms/step - loss: 1.0103 - accuracy: 0.8967 - val_loss: 0.8513 - val_accuracy: 0.8968\n","Epoch 5/100\n","563/563 [==============================] - 230s 408ms/step - loss: 0.7219 - accuracy: 0.9180 - val_loss: 0.6878 - val_accuracy: 0.8870\n","Epoch 6/100\n","563/563 [==============================] - 229s 408ms/step - loss: 0.5447 - accuracy: 0.9291 - val_loss: 0.6063 - val_accuracy: 0.8879\n","Epoch 7/100\n","563/563 [==============================] - 229s 407ms/step - loss: 0.4472 - accuracy: 0.9307 - val_loss: 0.5821 - val_accuracy: 0.8888\n","Epoch 8/100\n","563/563 [==============================] - 229s 406ms/step - loss: 0.3706 - accuracy: 0.9429 - val_loss: 0.5517 - val_accuracy: 0.8799\n","Epoch 9/100\n","563/563 [==============================] - 229s 408ms/step - loss: 0.3288 - accuracy: 0.9471 - val_loss: 0.5877 - val_accuracy: 0.8906\n","Epoch 10/100\n","563/563 [==============================] - 228s 406ms/step - loss: 0.2804 - accuracy: 0.9520 - val_loss: 1.2058 - val_accuracy: 0.8737\n","Epoch 11/100\n","563/563 [==============================] - 228s 406ms/step - loss: 0.2520 - accuracy: 0.9574 - val_loss: 0.4933 - val_accuracy: 0.8968\n","Epoch 12/100\n","563/563 [==============================] - 229s 406ms/step - loss: 0.2348 - accuracy: 0.9569 - val_loss: 0.4495 - val_accuracy: 0.8950\n","Epoch 13/100\n","563/563 [==============================] - 228s 404ms/step - loss: 0.2217 - accuracy: 0.9562 - val_loss: 0.4452 - val_accuracy: 0.9110\n","Epoch 14/100\n","563/563 [==============================] - 228s 404ms/step - loss: 0.2020 - accuracy: 0.9609 - val_loss: 1.3051 - val_accuracy: 0.8665\n","Epoch 15/100\n","563/563 [==============================] - 227s 404ms/step - loss: 0.1893 - accuracy: 0.9616 - val_loss: 0.4205 - val_accuracy: 0.8826\n","Epoch 16/100\n","563/563 [==============================] - 230s 409ms/step - loss: 0.1872 - accuracy: 0.9631 - val_loss: 0.4924 - val_accuracy: 0.8941\n","Epoch 17/100\n","563/563 [==============================] - 230s 408ms/step - loss: 0.1708 - accuracy: 0.9669 - val_loss: 0.3685 - val_accuracy: 0.9012\n","Epoch 18/100\n","563/563 [==============================] - 230s 409ms/step - loss: 0.1534 - accuracy: 0.9680 - val_loss: 0.8770 - val_accuracy: 0.8719\n","Epoch 19/100\n","563/563 [==============================] - 230s 409ms/step - loss: 0.1611 - accuracy: 0.9685 - val_loss: 0.3509 - val_accuracy: 0.9155\n","Epoch 20/100\n","563/563 [==============================] - 231s 411ms/step - loss: 0.1396 - accuracy: 0.9751 - val_loss: 0.4662 - val_accuracy: 0.8826\n","Epoch 21/100\n","563/563 [==============================] - 231s 411ms/step - loss: 0.1374 - accuracy: 0.9711 - val_loss: 0.4211 - val_accuracy: 0.9030\n","Epoch 22/100\n","563/563 [==============================] - 232s 413ms/step - loss: 0.1212 - accuracy: 0.9780 - val_loss: 0.3578 - val_accuracy: 0.9048\n","Epoch 23/100\n","563/563 [==============================] - 233s 414ms/step - loss: 0.1235 - accuracy: 0.9751 - val_loss: 0.4053 - val_accuracy: 0.9093\n","Epoch 24/100\n","563/563 [==============================] - 233s 413ms/step - loss: 0.1178 - accuracy: 0.9751 - val_loss: 0.3402 - val_accuracy: 0.9101\n","Epoch 25/100\n","563/563 [==============================] - 233s 414ms/step - loss: 0.1091 - accuracy: 0.9800 - val_loss: 0.4580 - val_accuracy: 0.8932\n","Epoch 26/100\n","563/563 [==============================] - 240s 426ms/step - loss: 0.1138 - accuracy: 0.9782 - val_loss: 0.5341 - val_accuracy: 0.8835\n","Epoch 27/100\n","563/563 [==============================] - 239s 425ms/step - loss: 0.1037 - accuracy: 0.9798 - val_loss: 0.3468 - val_accuracy: 0.9101\n","Epoch 28/100\n","563/563 [==============================] - 237s 421ms/step - loss: 0.1048 - accuracy: 0.9798 - val_loss: 0.5122 - val_accuracy: 0.8959\n","Epoch 29/100\n","563/563 [==============================] - 235s 417ms/step - loss: 0.1110 - accuracy: 0.9782 - val_loss: 0.3713 - val_accuracy: 0.9101\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fdb7e6ec2e8>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"xrzsEpVEpx_N"},"source":["Second finetuning: keep patience value to 5 for Early Stopping and freeze layers until the 28th. Now 22 more layers' weights are trained starting from the obtained results. Learning rate is decreased to 1e-5."]},{"cell_type":"code","metadata":{"id":"Tyyr63lpwzJ0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605819735437,"user_tz":-60,"elapsed":9448171,"user":{"displayName":"Davide Caffù","photoUrl":"","userId":"02628019914579525099"}},"outputId":"181634ca-59d3-436f-b774-417c87d86cd9"},"source":["# Early Stopping\n","\n","early_stop = True\n","if early_stop:\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n","    callbacks.append(es_callback)\n","    \n","    finetuning = True\n","\n","if finetuning:\n","    freeze_until = 28        # layer from which we want to fine-tune\n","    \n","    for layer in Inc.layers[:freeze_until]:\n","        layer.trainable = False\n","    for layer in Inc.layers[freeze_until:]:\n","        layer.trainable = True\n","\n","lr = 1e-5\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)   \n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)    \n","model.fit(x=train_dataset,\n","          epochs=100,\n","          steps_per_epoch=len(train_gen),\n","          validation_data=valid_dataset,\n","          validation_steps=len(valid_gen), \n","          callbacks=callbacks)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","563/563 [==============================] - 238s 422ms/step - loss: 0.1189 - accuracy: 0.9736 - val_loss: 0.3744 - val_accuracy: 0.9021\n","Epoch 2/100\n","563/563 [==============================] - 233s 414ms/step - loss: 0.0861 - accuracy: 0.9820 - val_loss: 0.3306 - val_accuracy: 0.9173\n","Epoch 3/100\n","563/563 [==============================] - 233s 414ms/step - loss: 0.0809 - accuracy: 0.9856 - val_loss: 0.3499 - val_accuracy: 0.9146\n","Epoch 4/100\n","563/563 [==============================] - 233s 414ms/step - loss: 0.0668 - accuracy: 0.9898 - val_loss: 0.3660 - val_accuracy: 0.9119\n","Epoch 5/100\n","563/563 [==============================] - 236s 419ms/step - loss: 0.0734 - accuracy: 0.9891 - val_loss: 0.3739 - val_accuracy: 0.9164\n","Epoch 6/100\n","563/563 [==============================] - 237s 420ms/step - loss: 0.0642 - accuracy: 0.9918 - val_loss: 0.3572 - val_accuracy: 0.9110\n","Epoch 7/100\n","563/563 [==============================] - 233s 414ms/step - loss: 0.0622 - accuracy: 0.9902 - val_loss: 0.3646 - val_accuracy: 0.9093\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fdb30b42cc0>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"NLO9zlRDGL1b"},"source":["Third finetuning: unlock 7 more layers to be trained and use half of the previous learning rate. The Patience for the Early Stopping is reduced to 3."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GeeCRiqYGMSq","executionInfo":{"status":"ok","timestamp":1605821421313,"user_tz":-60,"elapsed":11133134,"user":{"displayName":"Davide Caffù","photoUrl":"","userId":"02628019914579525099"}},"outputId":"94ee6b8c-1f62-49db-a477-66e2e7eaa32e"},"source":["# Early Stopping\n","\n","early_stop = True\n","if early_stop:\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n","    callbacks.append(es_callback)\n","    \n","    finetuning = True\n","\n","if finetuning:\n","    freeze_until = 21        # layer from which we want to fine-tune\n","    \n","    for layer in Inc.layers[:freeze_until]:\n","        layer.trainable = False\n","    for layer in Inc.layers[freeze_until:]:\n","        layer.trainable = True\n","\n","lr = 0.5*1e-5\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)   \n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)    \n","model.fit(x=train_dataset,\n","          epochs=100,\n","          steps_per_epoch=len(train_gen),\n","          validation_data=valid_dataset,\n","          validation_steps=len(valid_gen), \n","          callbacks=callbacks)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","563/563 [==============================] - 237s 420ms/step - loss: 0.0552 - accuracy: 0.9924 - val_loss: 0.3834 - val_accuracy: 0.9137\n","Epoch 2/100\n","563/563 [==============================] - 236s 419ms/step - loss: 0.0485 - accuracy: 0.9940 - val_loss: 0.3738 - val_accuracy: 0.9181\n","Epoch 3/100\n","563/563 [==============================] - 236s 419ms/step - loss: 0.0508 - accuracy: 0.9933 - val_loss: 0.3816 - val_accuracy: 0.9199\n","Epoch 4/100\n","563/563 [==============================] - 239s 424ms/step - loss: 0.0464 - accuracy: 0.9956 - val_loss: 0.3262 - val_accuracy: 0.9270\n","Epoch 5/100\n","563/563 [==============================] - 244s 433ms/step - loss: 0.0458 - accuracy: 0.9951 - val_loss: 0.3535 - val_accuracy: 0.9173\n","Epoch 6/100\n","563/563 [==============================] - 238s 423ms/step - loss: 0.0480 - accuracy: 0.9951 - val_loss: 0.3495 - val_accuracy: 0.9146\n","Epoch 7/100\n","563/563 [==============================] - 238s 422ms/step - loss: 0.0461 - accuracy: 0.9940 - val_loss: 0.3595 - val_accuracy: 0.9119\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fd94c534e10>"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"xV3OrJh32O1x"},"source":["Test the model and export results"]},{"cell_type":"code","metadata":{"id":"pc8GgNzVeLWZ"},"source":["import os\n","from PIL import Image\n","cwd = os.getcwd()\n","\n","dir = os.path.join('/content/drive/My Drive/Progetto/', 'test')\n","results = {}\n","for subdir, dirs, files in os.walk(dir):\n","    for file in files:\n","        filepath = subdir + os.sep + file\n","        img = Image.open(filepath).convert('RGB')\n","        img =img.resize((img_height,img_width))\n","        img_array = np.array(img)\n","        img_array = np.expand_dims(img_array, 0) \n","        img_tensor=tf.convert_to_tensor(img_array)\n","        img_tensor = tf.cast(img_array,tf.float32)/255.\n","        softmax=model(img_tensor)\n","        prediction = np.argmax(softmax)   # predicted class\n","        results[file] = prediction"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iSniBEyrHt94"},"source":["results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_pKi5BDaqJhr"},"source":["import os\n","from datetime import datetime\n","\n","def create_csv(results, results_dir='/content/drive/My Drive/MaskDataset/Results'):\n","\n","    csv_fname = 'results_inception_'\n","    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n","\n","    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n","\n","        f.write('Id,Category\\n')\n","\n","        for key, value in results.items():\n","            f.write(key + ',' + str(value) + '\\n')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Nxhbkkzqrk2"},"source":["create_csv(results)"],"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TL_model.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ybyKhjNDrfbO"},"source":["# Transfer Learning approach - VGG16\n","This is the notebook model used to apply transfer learning to solve the classification task."]},{"cell_type":"markdown","metadata":{"id":"6s998L4ur-C5"},"source":["Import the needed libraries and connect Drive:"]},{"cell_type":"code","metadata":{"id":"NlVIKsRvQiUQ"},"source":["from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j5hKGPULQjct"},"source":["import os\n","import tensorflow as tf\n","import numpy as np\n","import shutil\n","\n","SEED = 1518\n","tf.random.set_seed(SEED)  \n","\n","# Get current working directory\n","cwd = os.getcwd()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ZNqh4LDcnjW"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","os.getcwd()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qvpn-gBLeMxc"},"source":["# Get dataset directory\n","dataset_dir = os.path.join(cwd, 'drive/My Drive/MaskDataset')\n","dataset_dir\n","train_dir =os.path.join(dataset_dir,'training')\n","test_dir = os.path.join(dataset_dir, 'test')\n","os.listdir(dataset_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9O3J00MStk0A"},"source":["Split the training set into training and validation and create ImageDataGenerator objects.\n","Data augmentation is applied based on the True or False value for the if condition.\n","When applied, it consists in image rotation, shift, horizontal flip and zoom.\n","In both cases, the pixel values are normalized in order to have values between 0 and 1."]},{"cell_type":"code","metadata":{"id":"mzOR4Mn-Q9Iw"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","apply_data_augmentation = True\n","\n","# Create training ImageDataGenerator object\n","if apply_data_augmentation:\n","    train_data_gen = ImageDataGenerator(rotation_range=10,\n","                                        width_shift_range=5,\n","                                        height_shift_range=5,\n","                                        zoom_range=0.2,\n","                                        horizontal_flip=True,\n","                                        vertical_flip=False,\n","                                        fill_mode='nearest',\n","                                        rescale=1./255,\n","                                        validation_split=0.15)\n","else:\n","    train_data_gen = ImageDataGenerator(rescale=1./255,\n","                                        validation_split=0.15)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mYMRU072ukQ-"},"source":["Set batch size and image shape in which the elements of training and validation dataset will be created. Shuffle and seed are applied. Due to our previous separation of images into classes folders in the training set we can now set the class mode to categorical."]},{"cell_type":"code","metadata":{"id":"5nIjmwVDxpMF"},"source":["# Batch size\n","bs = 12\n","\n","# Output image shape\n","img_width = 256\n","img_height = 256\n","\n","# Classes\n","num_classes = 3\n","\n","# Generate Training & Validation \n","train_gen = train_data_gen.flow_from_directory(train_dir,\n","                                               batch_size=bs,\n","                                               classes=None,\n","                                               class_mode='categorical', # automatic 1-hot encoding\n","                                               color_mode='rgb',        \n","                                               shuffle=True,\n","                                               subset='training',\n","                                               seed=SEED) \n","\n","valid_gen = train_data_gen.flow_from_directory(train_dir,\n","                                               batch_size=bs,\n","                                               classes=None,\n","                                               class_mode='categorical',\n","                                               color_mode='rgb',        \n","                                               shuffle=True,\n","                                               subset='validation',\n","                                               seed=SEED)\n","\n","# Training set creation (85pc) and validation set creation(15pc)\n","train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([None, img_height, img_width, 3], [None, num_classes]))\n","\n","valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([None, img_height, img_width, 3], [None, num_classes]))\n","\n","# Adding repetition of elements for the next epochs\n","train_dataset.repeat()\n","valid_dataset.repeat()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"87KkmM7Vwtlu"},"source":["Load the model to use for transfer learning. In this case the chosen model is VGG16, directly available in the applications section of Keras. Loaded weights are the ones of the network trained on the *ImageNet* database. The fully-connected part is removed by setting include_top to False."]},{"cell_type":"code","metadata":{"id":"H6jkcc69hEcN"},"source":["# Load VGG16 Model\n","\n","vgg = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IZiajI6dxTxx"},"source":["Create the model by setting which weights of the pretrained model have to be trained again on our training set and designing the new fully-connected part. Here only the last convolutional layer of the VGG16 is retrained."]},{"cell_type":"code","metadata":{"id":"AWIxwN3l5a9f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"206f5c62-7b51-4e2e-865d-10378a4c8d0a"},"source":["# Create Model\n","\n","finetuning = True\n","\n","if finetuning:\n","    freeze_until = 14   # layer from which we want to fine-tune\n","    \n","    for layer in vgg.layers[:freeze_until]:\n","        layer.trainable = False\n","else:\n","    vgg.trainable = False\n","    \n","model = tf.keras.Sequential()\n","model.add(vgg)\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n","model.add(tf.keras.layers.Dropout(0.4))\n","model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n","model.add(tf.keras.layers.Dropout(0.2))\n","model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n","\n","# Model summary\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Functional)           (None, 8, 8, 512)         14714688  \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 32768)             0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 256)               8388864   \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 64)                16448     \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 3)                 195       \n","=================================================================\n","Total params: 23,120,195\n","Trainable params: 15,484,931\n","Non-trainable params: 7,635,264\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"69WsmMQ9x8KA"},"source":["Set optimization parameters: loss, optimizer and metrics"]},{"cell_type":"code","metadata":{"id":"SWGIerWJx5c4"},"source":["# Loss function\n","loss = tf.keras.losses.CategoricalCrossentropy()\n","\n","# Learning rate\n","lr = 1e-4\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","\n","# Validation metrics\n","metrics = ['accuracy']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UbpxvWN8yOVw"},"source":["# Compile Model\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qACMJd0IyWqY"},"source":["Load tensorboard (uncomment to load)"]},{"cell_type":"code","metadata":{"id":"oEFBqJpWgQ04"},"source":["#%reload_ext tensorboard\n","#%tensorboard --logdir /content/drive/My\\ Drive/MaskDataset/classification_experiments --port 8008"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TtZBTnajy-Yi"},"source":["Set callbacks and visualization of losses and metrics on Tensorboard"]},{"cell_type":"code","metadata":{"id":"X9yj1Wrjd_1i"},"source":["# Callbacks\n","from datetime import datetime\n","\n","\n","cwd = os.getcwd()\n","\n","exps_dir = os.path.join('/content/drive/My Drive/MaskDataset/', 'classification_experiments_VGG_3')\n","if not os.path.exists(exps_dir):\n","    os.makedirs(exps_dir)\n","\n","now = datetime.now().strftime('%b%d_%H-%M-%S')\n","\n","model_name = 'CNN_1'\n","\n","exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n","if not os.path.exists(exp_dir):\n","    os.makedirs(exp_dir)\n","    \n","callbacks = []\n","\n","# Visualize Learning on Tensorboard\n","tb_dir = os.path.join(exp_dir, 'tb_logs')\n","if not os.path.exists(tb_dir):\n","    os.makedirs(tb_dir)\n","    \n","# Show losses and metrics for both training and validation\n","tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n","                                             profile_batch=0,\n","                                             histogram_freq=1)\n","callbacks.append(tb_callback)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ilVECNLKy5Ig"},"source":["Activate Early Stopping to reduce overfitting"]},{"cell_type":"code","metadata":{"id":"bgIX5RWLy3iF"},"source":["# Early Stopping\n","early_stop = True\n","if early_stop:\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n","    callbacks.append(es_callback)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"joqc57sf0Sqj"},"source":["Fit the model after setting the number of epochs and the number of steps for each epoch."]},{"cell_type":"code","metadata":{"id":"UgEr-3kmfEWy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"323ed010-7891-4436-97c6-9b3019ee9610"},"source":["model.fit(x = train_dataset,\n","          epochs = 100,\n","          steps_per_epoch = len(train_gen),\n","          validation_data = valid_dataset,\n","          validation_steps = len(valid_gen), \n","          callbacks = callbacks)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<FlatMapDataset shapes: ((None, 256, 256, 3), (None, 3)), types: (tf.float32, tf.float32)>"]},"metadata":{"tags":[]},"execution_count":35},{"output_type":"execute_result","data":{"text/plain":["<FlatMapDataset shapes: ((None, 256, 256, 3), (None, 3)), types: (tf.float32, tf.float32)>"]},"metadata":{"tags":[]},"execution_count":35},{"output_type":"stream","text":["Epoch 1/100\n","399/399 [==============================] - 147s 369ms/step - loss: 0.8509 - accuracy: 0.5632 - val_loss: 0.6506 - val_accuracy: 0.6643\n","Epoch 2/100\n","399/399 [==============================] - 146s 366ms/step - loss: 0.6173 - accuracy: 0.6966 - val_loss: 0.5137 - val_accuracy: 0.7628\n","Epoch 3/100\n","399/399 [==============================] - 146s 366ms/step - loss: 0.5523 - accuracy: 0.7466 - val_loss: 0.5701 - val_accuracy: 0.7307\n","Epoch 4/100\n","399/399 [==============================] - 146s 365ms/step - loss: 0.4996 - accuracy: 0.7771 - val_loss: 0.4803 - val_accuracy: 0.7805\n","Epoch 5/100\n","399/399 [==============================] - 146s 366ms/step - loss: 0.4293 - accuracy: 0.8125 - val_loss: 0.4143 - val_accuracy: 0.8197\n","Epoch 6/100\n","399/399 [==============================] - 146s 367ms/step - loss: 0.3974 - accuracy: 0.8246 - val_loss: 0.4238 - val_accuracy: 0.8316\n","Epoch 7/100\n","399/399 [==============================] - 147s 369ms/step - loss: 0.3714 - accuracy: 0.8424 - val_loss: 0.5658 - val_accuracy: 0.7805\n","Epoch 8/100\n","399/399 [==============================] - 147s 368ms/step - loss: 0.3090 - accuracy: 0.8691 - val_loss: 0.3857 - val_accuracy: 0.8292\n","Epoch 9/100\n","399/399 [==============================] - 147s 369ms/step - loss: 0.3003 - accuracy: 0.8844 - val_loss: 0.4043 - val_accuracy: 0.8351\n","Epoch 10/100\n","399/399 [==============================] - 146s 367ms/step - loss: 0.2615 - accuracy: 0.8994 - val_loss: 0.4431 - val_accuracy: 0.8327\n","Epoch 11/100\n","399/399 [==============================] - 147s 367ms/step - loss: 0.2319 - accuracy: 0.9137 - val_loss: 0.3561 - val_accuracy: 0.8529\n","Epoch 12/100\n","399/399 [==============================] - 147s 369ms/step - loss: 0.2113 - accuracy: 0.9178 - val_loss: 0.3725 - val_accuracy: 0.8695\n","Epoch 13/100\n","399/399 [==============================] - 147s 369ms/step - loss: 0.1857 - accuracy: 0.9331 - val_loss: 0.4098 - val_accuracy: 0.8482\n","Epoch 14/100\n","399/399 [==============================] - 148s 370ms/step - loss: 0.1605 - accuracy: 0.9425 - val_loss: 0.5497 - val_accuracy: 0.8363\n","Epoch 15/100\n","399/399 [==============================] - 147s 368ms/step - loss: 0.1577 - accuracy: 0.9456 - val_loss: 0.5473 - val_accuracy: 0.8351\n","Epoch 16/100\n","399/399 [==============================] - 147s 368ms/step - loss: 0.1307 - accuracy: 0.9538 - val_loss: 0.4796 - val_accuracy: 0.8280\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f96f0580ba8>"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"jhPJTqPyzn0_"},"source":["Test the model on the test set and make predictions."]},{"cell_type":"code","metadata":{"id":"_AKJNuCsw8A7"},"source":["import os\n","from PIL import Image\n","cwd = os.getcwd()\n","\n","dir = os.path.join('/content/drive/My Drive/MaskDataset/', 'test')\n","results = {}\n","for subdir, dirs, files in os.walk(dir):\n","    for file in files:\n","        filepath = subdir + os.sep + file\n","        img = Image.open(filepath).convert('RGB')\n","        img = img.resize((img_height,img_width))\n","        img_array = np.array(img)\n","        img_array = np.expand_dims(img_array, 0) \n","        img_tensor = tf.convert_to_tensor(img_array)\n","        img_tensor = tf.cast(img_array,tf.float32)/255.\n","        softmax = model.predict(img_tensor)\n","        prediction = np.argmax(softmax)   # predicted class\n","        results[file] = prediction\n","        \n","        \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s3JX-W42zz7G"},"source":["Create the CSV file from the obtained predictions that will be submitted in order to have a score for the model."]},{"cell_type":"code","metadata":{"id":"zyGQDaYqxCPI"},"source":["import os\n","from datetime import datetime\n","\n","def create_csv(results, results_dir='/content/drive/My Drive/Progetto/Results'):\n","\n","    csv_fname = 'results_'\n","    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n","\n","    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n","\n","        f.write('Id,Category\\n')\n","\n","        for key, value in results.items():\n","            f.write(key + ',' + str(value) + '\\n')"],"execution_count":null,"outputs":[]}]}